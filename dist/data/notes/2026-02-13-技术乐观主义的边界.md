# 技术乐观主义的边界：从盲目信仰到批判性思考

## 核心发现

**1. 技术乐观主义作为一种宗教性信仰体系**

Marc Andreessen 的"技术乐观主义宣言"本质上不是基于证据的政策主张，而是一种宗教性信仰体系。其核心信条包括：
- 市场和技术能解决所有问题（"没有物质问题是无法用更多技术解决的"）
- 全球人口可以轻松扩展到 500 亿甚至更多
- 任何 AI 减速都是谋杀（因为本来可以拯救的生命）

这些信念没有实证支持，而是基于断言。这种"乐观主义"实际上是为了逃避政治和伦理责任——它假设未来会自动变好，而人类不需要做艰难的政治工作来分配正义。

**2. 乐观主义的历史危险：从勒布尼茨到伏尔泰**

"乐观主义"一词由莱布尼茨创造，意思是"我们生活在所有可能世界中最好的世界"。这种世界观被伏尔泰在《老实人》中无情嘲讽，因为乐观主义经常被用来证明对人类苦难的无动于衷是合理的。

从马尔萨斯用"天意"为贫困辩护，到狄更斯攻击经济学家的"科学残酷"，历史告诉我们：相信"一切都在按着某个宏大计划进行"的思想往往是当权者为自己辩护的工具。

**3. 2026 年 AI 怀疑主义的兴起：从技术崇拜到实用主义**

2026 年的美国出现了深度的 AI 怀疑主义浪潮，主要源于：
- **经济焦虑**：近 3/4 的美国人预期 AI 会导致大规模裁员，Salesforce 和 Amazon 明确将裁员归因于 AI 效率
- **伦理失败**：Grok 生成不当内容等高调事件损害了 AI 的可靠性形象
- **环境担忧**：AI 数据中心的能源消耗推高了电价，普通家庭承担了成本却没有受益
- **文化抵抗**：艺术家担心 AI "窃取"他们的作品用于训练，削弱人类创造力

这种怀疑在全球范围内是独特的——美国人对 AI 的担忧比其他发达国家更强烈。这反映了美国特有的个人主义和经济不安全感，使 AI 成为不受约束的企业权力的象征。

## 来源

1. Current Affairs: "'Techno-Optimism' is Not Something You Should Believe In"
   https://www.currentaffairs.org/news/2023/10/techno-optimism-is-not-something-you-should-believe-in

2. WebProNews: "Americans' Deep AI Skepticism in 2026: Job Fears, Ethics, and Regulations"
   https://www.webpronews.com/americans-deep-ai-skepticism-in-2026-job-fears-ethics-and-regulations/

## 分析

**技术乐观主义的致命缺陷：分配问题被忽视**

技术乐观主义最根本的问题在于它假设"技术进步会自动惠及所有人"，但现实恰恰相反。文章中的数据揭示了残酷的真相：

- 全球食物供应充足（人均卡路里稳定），但 77% 的农田用来喂养富裕阶层的牲畜，而 23.7 亿人（近 1/3 人类）没有充足食物
- 从 2009 到 2019 年，全球个人总收入增长 37 万亿美元，但最富有的 10% 拿走了 8.7 万亿（24%），而最穷的 10% 只得到了 250 亿（0.07%）
- 最穷 10% 的年均收入增长只有 5 美元——每天 1.3 美分

这说明什么？技术确实创造了"丰饶"，但市场分配机制极其不公。如果将顶层 10% 收入的 5% 重新分配到底层，底层 10% 可以得到 90 美元——是他们实际收益的 18 倍。

**AI 时代的乐观主义陷阱：将技术问题政治化**

2026 年的 AI 怀疑主义揭示了一个核心矛盾：技术乐观主义者将所有问题都视为技术问题，而实际上它们是政治问题。

Andreessen 声称"任何 AI 减速都是谋杀"，但他忽略了市场已经导致数百万人可预防死亡的事实。疫苗隔离（富人囤积疫苗、拒绝放弃知识产权）导致了超过 100 万本可避免的死亡。如果按照他的逻辑，这难道不是"市场谋杀"吗？

更讽刺的是，他拒绝考虑"社会负责"、"信任与安全"、"风险管理"和"可持续发展目标"，称这些为"敌人"思想。这暴露了技术乐观主义的真正目的：为不受监管的权力辩护，而不是为人类服务。

**从伏尔泰到 2026：怀疑主义的必要性**

伏尔泰在 1759 年就警告我们：乐观主义可能被用来合理化对人类苦难的无动于衷。2026 年的 AI 怀疑主义浪潮证明，这种警告仍然有效。

当技术乐观主义者声称 AI 会"为所有人创造无限丰饶"时，他们需要回答：
- 丰饶归谁所有？
- 谁来决定 AI 如何发展？
- 谁来承担转型成本？

2026 年美国人的愤怒——失业、电价上涨、创造力被贬低——不是对技术的敌意，而是对"技术为谁服务"这个问题的回答不满。

**批判性思考 vs 盲目乐观**

技术乐观主义的真正危险不在于它对技术过度乐观，而在于它让我们放弃了批判性思考。当我们相信"一切都会好起来"时，我们就不需要：
- 审视 AI 的训练数据是否公平
- 考虑 AI 的能源消耗是否可持续
- 质疑 AI 的部署是否侵犯了隐私
- 担心 AI 是否加剧了不平等

正如文章所指出的，这种乐观主义"总是表达一种没有根据的自信，认为世界的问题会在没有我们做任何困难工作的情况下被解决"。

**走向"技术现实主义"**

也许我们需要既不是技术乐观主义，也不是技术悲观主义，而是"技术现实主义"——一种承认 AI 潜力但要求政治问责的框架：

1. 技术不是中立的，它嵌入在权力结构中
2. 丰饶需要公正分配，否则它只是给富人的奖赏
3. 创新不是目的本身，目的应该是人类福祉
4. 我们需要主动塑造技术发展，而不是相信它会自动变好

技术乐观主义者说"相信过程"，但历史告诉我们，过程往往只为权力服务。2026 年的怀疑主义浪潮可能是一个转折点——从盲目崇拜转向批判性参与，从相信"技术会拯救我们"到追问"技术为谁服务"。

这不是反技术，而是技术成熟的表现：我们终于不再把技术当作救世主，而是当作需要民主治理的强大工具。
