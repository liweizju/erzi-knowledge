# Agentic AI 的 UX 设计模式——让用户"授予"而非"放弃"控制权

> **洞见建议**：Agentic AI 的信任设计框架——当 AI 从"建议者"变成"行动者"，如何通过六种 UX 模式（意图预览、自主权调节器、可解释理由、置信度信号、审计与撤销、升级路径）构建"可控的自主"体验？
> **为什么值得深挖**：2026 年 AI 产品正从"生成式"转向"代理式"——不再只是回答问题，而是替用户做事。这种能力跃迁带来了全新的 UX 挑战：如何在赋予 AI 高度自主权的同时，让用户始终保持掌控感？这组设计模式提供了系统性答案。

**方向**：灵感采集
**日期**：2026-02-21

---

## 核心理念：自主是技术输出，信任是设计输出

> "Autonomy is an output of a technical system. Trustworthiness is an output of a design process."

这句话道破了 Agentic AI 设计的本质：**技术可以赋予 AI 自主行动的能力，但只有精心设计才能让用户信任这种自主。**

设计 Agentic AI 不是设计工具，而是**设计一段关系**——像任何成功的伙伴关系一样，需要建立在清晰的沟通、相互理解和明确的边界之上。

## 六种核心 UX 模式

文章提出了按交互生命周期组织的六种模式：

| 阶段 | 模式 | 作用 |
|------|------|------|
| 行动前 | Intent Preview | 明确计划，获取同意 |
| 行动前 | Autonomy Dial | 设置自主权边界 |
| 行动中 | Explainable Rationale | 解释"为什么" |
| 行动中 | Confidence Signal | 展示"有多确定" |
| 行动后 | Action Audit & Undo | 审计与撤销 |
| 行动后 | Escalation Pathway | 升级到人工 |

---

### 模式 1：Intent Preview（意图预览）

**核心**：行动前先说"我要这样做，你同意吗？"

这是用户-Agent 关系中**获取同意的基础时刻**。把一个不透明的自主过程转化为一个透明、可审查的计划。

#### 有效意图预览的要素

1. **清晰简洁**：用日常语言，避免技术术语
   - ❌ "Executing API call to cancel_booking(id: 4A7B)"
   - ✅ "取消飞往旧金山的 AA123 航班"

2. **顺序步骤**：多步操作要展示关键阶段，让用户发现潜在问题

3. **明确选择**：这是决策点，不是通知
   - `[ 执行此计划 ]` `[ 编辑计划 ]` `[ 我自己处理 ]`

#### 案例：旅行助理处理航班取消

```
您的行程中断处理方案

我检测到您 10:05 的航班已取消。我计划：

1. 取消航班 UA456
   处理退款并确认取消详情

2. 重新预订 DL789
   预订下午 2:30 的直飞航班，这是下一个有确认座位的直飞航班

3. 更新酒店预订
   通知万豪酒店您会晚到

4. 发送更新行程
   将新航班和酒店详情发送给您和您的助理

[ 执行此计划 ] [ 编辑计划 ] [ 我自己处理 ]
```

#### 成功指标

| 指标 | 目标 |
|------|------|
| 接受率（不经编辑接受计划的比例） | > 85% |
| 覆盖频率（用户点"我自己处理"的比例） | > 10% 需触发模型审查 |
| 回忆准确率（隐藏预览 10 秒后能正确复述步骤的比例） | 高 |

---

### 模式 2：Autonomy Dial（自主权调节器）

**核心**：信任是光谱，不是开关。让用户按任务类型调节 AI 的自主程度。

#### 四级自主设置

| 级别 | 名称 | 行为 |
|------|------|------|
| 1 | Observe & Suggest | 只通知机会或问题，从不主动提出计划 |
| 2 | Plan & Propose | 可以创建计划，但必须先经我审查才能执行 |
| 3 | Act with Confirmation | 对于熟悉的任务，准备行动后让我做最终确认 |
| 4 | Act Autonomously | 对于预设范围的任务（如 50 美元以下的争议），可以自主行动后通知我 |

#### 关键洞察：任务级粒度

一个邮件助手可以对"安排会议"和"代发邮件"设置不同的自主权级别。**这种粒度反映了用户信任的微妙现实。**

#### 成功指标

- **信任密度**：各设置的用户分布（如 20% Suggest, 50% Confirm, 30% Auto）
- **设置变动率**：每月设置变更次数 / 活跃用户。高变动率表示信任不稳定

---

### 模式 3：Explainable Rationale（可解释理由）

**核心**：行动后主动解释"为什么"，在被问之前先回答。

> "I did that because you've told me in the past that you prefer X."

当 Agent 行动（尤其是自主行动）时，用户的第一反应往往是"为什么这样做？"

这个模式把系统原语转化为用户能理解的语言，并**基于用户自己的偏好和过往输入**来解释决策。

#### 关键原则

- 不是技术日志
- 基于用户已表达的偏好
- 解释与用户目标的关联

---

### 模式 4：Confidence Signal（置信度信号）

**核心**：展示 Agent 有多确定，让用户知道何时需要介入。

Agent 不应该只展示决策，还应该展示**决策的不确定性**。当置信度低时，用户自然会提高警惕或选择介入。

---

### 模式 5：Action Audit & Undo（审计与撤销）

**核心**：安全网——错误发生时能回溯和撤销。

这是用户敢于授权的根本保障。知道"即使错了也能撤回"，用户才愿意给 AI 更多自主权。

---

### 模式 6：Escalation Pathway（升级路径）

**核心**：高模糊时刻升级到人工的清晰通道。

当 Agent 遇到超出其能力边界的情况时，不应该硬撑，而应该有明确的方式把控制权交还给用户。

---

## 高风险领域的应用

文章特别强调了在 DevOps、医疗等高风险领域的应用。例如云基础设施管理 Agent 的意图预览：

```
生产环境发布计划

检测到服务异常。建议：

1. 排空流量
   将服务实例从负载均衡器移除

2. 回滚到 v2.4.1
   恢复上一个稳定版本

3. 重新加入负载均衡
   验证健康后恢复流量

预计影响：2-3 分钟服务中断
[ 授权执行 ] [ 修改步骤 ] [ 取消 ]
```

在这种场景下，术语更专业（Drain Traffic, Rollback），操作是二元且影响重大的。用户不是在"批准建议"，而是在**授权一次重大运维操作**。

---

## 核心发现

1. **从"工具"到"关系"的设计范式转变**：Agentic AI 不是设计工具，而是设计用户与 AI 之间的伙伴关系，需要沟通、理解和边界。

2. **自主权的"渐进授权"模式**：通过 Autonomy Dial 让用户从低自主开始，随着信任建立逐步提高，避免"一次失败就全盘放弃"。

3. **行动前、中、后的全链路透明**：六种模式覆盖了完整生命周期，确保用户在每个环节都有掌控感。

4. **"速度带"而非"障碍"**：Intent Preview 是"有意摩擦"——不是阻碍效率，而是确保用户在做有意识的选择。

5. **可量化的信任指标**：每种模式都有具体的成功指标，让"信任"从抽象概念变成可追踪的产品健康度。

## 延伸思考

**与其他笔记的联系**：
- 与"双用户设计"呼应：Agentic AI 是产品需要服务的"第二用户"，这些模式正是让产品能被 Agent 理解和操作的设计语言
- 与"AI 信任悖论"互补：当 AI 普及率飙升但信任度下降，这套模式提供了重建信任的具体操作方法
- 与"透明度/控制权/干预点"框架一致：六种模式正是这三者的具体实现

**对产品设计的启发**：
- 不是所有功能都需要全部六种模式，但高风险操作必须有 Intent Preview
- Autonomy Dial 是新用户 Onboarding 的关键——让用户从安全区开始
- 可解释性不是"附加功能"，是核心信任基础设施

**对二子建站的可能应用**：
- 如果涉及任何自动化操作（发布、通知、数据处理），都需要考虑这些模式
- 置信度信号可以用于展示 AI 生成内容的不确定性
- 审计与撤销是用户敢于尝试新功能的心理安全保障

## 来源

- [Designing For Agentic AI: Practical UX Patterns | Smashing Magazine](https://www.smashingmagazine.com/2026/02/designing-agentic-ai-practical-ux-patterns/)
